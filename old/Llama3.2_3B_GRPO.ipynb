{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd551ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load your tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('your-model-name')\n",
    "model = AutoModel.from_pretrained('your-model-name')\n",
    "\n",
    "assert len(tokenizer) == model.config.vocab_size, \"Tokenizer vocab size does not match model vocab size\"\n",
    "\n",
    "# Prepare your datasets (train_dataset, test_dataset) as needed\n",
    "# For example:\n",
    "# train_dataset = ...\n",
    "# test_dataset = ...\n",
    "\n",
    "# Import your custom trainer\n",
    "from your_trainer_module import GRPOTrainer\n",
    "\n",
    "# Initialize the trainer using the tokenizer directly without chat templating\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    "    # Add other necessary arguments\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd5c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Modified Input Preparation Function ---\n",
    "# In your custom GRPOTrainer (likely in UnslothGRPOTrainer.py), locate the _prepare_inputs method.\n",
    "# Replace the chat template line with the following version that bypasses chat templating:\n",
    "\n",
    "def _prepare_inputs(self, inputs):\n",
    "    device = self.accelerator.device\n",
    "    # Assuming each input is a dict with a 'prompt' key\n",
    "    prompts = [x[\"prompt\"] for x in inputs]\n",
    "    \n",
    "    # Instead of applying a chat template, directly extract the prompt text\n",
    "    prompts_text = [example[\"prompt\"] for example in inputs]\n",
    "    \n",
    "    prompt_inputs = self.processing_class(\n",
    "        prompts_text, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True, \n",
    "        padding_side=\"left\", \n",
    "        add_special_tokens=False\n",
    "    )\n",
    "    \n",
    "    prompt_inputs = super()._prepare_inputs(prompt_inputs)\n",
    "    return prompt_inputs\n",
    "\n",
    "# Make sure your GRPOTrainer uses this updated version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a95c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Testing Output ---\n",
    "print(\"\\nTraining Data Test Results:\")\n",
    "for i, (prompt, completion, reward) in enumerate(zip(test_prompts, test_completions, rewards)):\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(\"Prompt:\", prompt[-1][\"content\"])  # Show last user prompt\n",
    "    print(\"Generated:\", completion[0][\"content\"][:100] + \"...\")\n",
    "    print(\"Reference Answer:\", test_answers[i][:100] + \"...\")\n",
    "    print(f\"Reward: {reward:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
